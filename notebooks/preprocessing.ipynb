{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc57641-567a-4bef-b7c4-ba4ddebc9403",
   "metadata": {},
   "source": [
    "# California Housing â€“ Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00c649d0-8e32-4f48-975c-a300fc789ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d833efc8-76e5-42d4-814d-ed73f00e7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame.copy()\n",
    "\n",
    "X = df.drop(columns=\"MedHouseVal\")\n",
    "y = df[\"MedHouseVal\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954caa2-16fb-4915-8b4a-8dbbd7bb1fea",
   "metadata": {},
   "source": [
    "### ------------------------\n",
    "## v1 (train/test only)\n",
    "### ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4519caf-289a-4fdf-82c8-5d70e941377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (20640, 8)\n",
      "y shape: (20640,)\n",
      "Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Features:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fdf8697-2dbf-437a-b51d-c5c92ae6c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (16512, 8) X_test: (4128, 8)\n",
      "y_train: (16512,) y_test: (4128,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape, \"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c2bf9d-4874-408e-9096-b9006430c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled shapes: (16512, 8) (4128, 8)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaled shapes:\", X_train_scaled.shape, X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "378a6897-78e7-4951-ba10-2d66905535db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean (first 5): [-6.51933288e-17 -9.25185854e-18 -1.98108110e-16 -1.70729064e-16\n",
      " -2.15159501e-19]\n",
      "Train std  (first 5): [1. 1. 1. 1. 1.]\n",
      "Test mean  (first 5): [-0.02647585  0.01237949 -0.01305925 -0.00011079 -0.00429306]\n",
      "Test std   (first 5): [0.9879485  0.99322892 1.17051691 1.4084032  0.97965408]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train mean (first 5):\", X_train_scaled.mean(axis=0)[:5])\n",
    "print(\"Train std  (first 5):\", X_train_scaled.std(axis=0)[:5])\n",
    "\n",
    "print(\"Test mean  (first 5):\", X_test_scaled.mean(axis=0)[:5])\n",
    "print(\"Test std   (first 5):\", X_test_scaled.std(axis=0)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d399a34-2ab6-4558-9a1c-c83002c4a221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved arrays to ../data/v1_train_test/\n"
     ]
    }
   ],
   "source": [
    "np.save(\"../data/v1_train_test/X_train_scaled.npy\", X_train_scaled)\n",
    "np.save(\"../data/v1_train_test/X_test_scaled.npy\",  X_test_scaled)\n",
    "np.save(\"../data/v1_train_test/y_train.npy\", y_train.to_numpy())\n",
    "np.save(\"../data/v1_train_test/y_test.npy\",  y_test.to_numpy())\n",
    "\n",
    "print(\"Saved arrays to ../data/v1_train_test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587ada4-16ee-42a1-921a-846b13c30d0a",
   "metadata": {},
   "source": [
    "### ------------------------\n",
    "## v2 (train/val/test)\n",
    "### ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56a36011-56c3-407b-a3f1-fac24622dc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2 X_train2: (13209, 8) X_val: (3303, 8) X_test: (4128, 8)\n",
      "v2 y_train2: (13209,) y_val: (3303,) y_test: (4128,)\n"
     ]
    }
   ],
   "source": [
    "# 1) Create validation split FROM the existing training set\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"v2 X_train2:\", X_train2.shape, \"X_val:\", X_val.shape, \"X_test:\", X_test.shape)\n",
    "print(\"v2 y_train2:\", y_train2.shape, \"y_val:\", y_val.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2884679-46ba-473c-9b85-fdf935509e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Fit a new scaler ONLY on X_train2 (no leakage)\n",
    "scaler_v2 = StandardScaler()\n",
    "X_train2_scaled = scaler_v2.fit_transform(X_train2)\n",
    "X_val_scaled    = scaler_v2.transform(X_val)\n",
    "X_test_scaled_v2 = scaler_v2.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f64b73-50b2-4254-a8b8-7a6776a52060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Save v2 arrays into a new folder\n",
    "v2_dir = \"../data/v2_train_val_test\"\n",
    "os.makedirs(v2_dir, exist_ok=True)\n",
    "\n",
    "np.save(f\"{v2_dir}/X_train_scaled.npy\", X_train2_scaled)\n",
    "np.save(f\"{v2_dir}/X_val_scaled.npy\",   X_val_scaled)\n",
    "np.save(f\"{v2_dir}/X_test_scaled.npy\",  X_test_scaled_v2)\n",
    "\n",
    "np.save(f\"{v2_dir}/y_train.npy\", y_train2.to_numpy())\n",
    "np.save(f\"{v2_dir}/y_val.npy\",   y_val.to_numpy())\n",
    "np.save(f\"{v2_dir}/y_test.npy\",  y_test.to_numpy())\n",
    "\n",
    "with open(f\"{v2_dir}/feature_names.json\", \"w\") as f:\n",
    "    json.dump(X.columns.tolist(), f)\n",
    "\n",
    "dump(scaler_v2, f\"{v2_dir}/scaler.joblib\")\n",
    "\n",
    "print(f\"Saved v2 arrays to {v2_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
